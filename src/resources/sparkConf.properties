spark.migrate.beta                                              false

spark.migrate.source.host                                       localhost
spark.migrate.source.username                                   some-username
spark.migrate.source.password                                   some-secret-password

spark.migrate.astra.scb                                         file:///aaa/bbb/secure-connect-enterprise.zip
spark.migrate.astra.username                                    client-id
spark.migrate.astra.password                                    client-secret

spark.cassandra.source.read.consistency.level                   LOCAL_QUORUM
spark.cassandra.astra.read.consistency.level                    LOCAL_QUORUM

spark.migrate.maxRetries                                        10
spark.migrate.readRateLimit                                     40000
spark.migrate.writeRateLimit                                    40000
spark.migrate.splitSize                                         5
spark.migrate.batchSize                                         5
spark.migrate.printStatsAfter                                   100000

spark.migrate.source.keyspaceTable                              test.a1
spark.migrate.astra.keyspaceTable                               test.a2

spark.migrate.query.cols.select                                 partition-key,clustering-key,order-date,amount,writetime(order-date),writetime(amount),ttl(order-date),ttl(amount)
spark.migrate.diff.select.types                                 9,1,4,3
spark.migrate.query.cols.id                                     partition-key,clustering-key
spark.migrate.query.cols.id.types                               9,1
spark.migrate.query.cols.partitionKey                           partition-key

spark.migrate.query.cols.insert                                 partition-key,clustering-key,order-date,amount
spark.migrate.query.cols.insert.types                           9,1,4,3

spark.migrate.source.counterTable                               false
spark.migrate.source.counterTable.update.cql
spark.migrate.source.counterTable.update.max.counter.index      0
spark.migrate.source.counterTable.update.select.index           0

spark.migrate.preserveTTLWriteTime                              true
spark.migrate.source.ttl.cols                                   6,7

spark.migrate.source.writeTimeStampFilter                       false
spark.migrate.source.writeTimeStampFilter.cols                  4,5
spark.migrate.source.minWriteTimeStampFilter                    0
spark.migrate.source.maxWriteTimeStampFilter                    9223372036854775807

spark.migrate.source.data.keyspaceTable                         test.grid_test
spark.migrate.astra.data.keyspaceTable                          test.grid_test2

/* Note: 
Enable "spark.migrate.preserveTTLWriteTime" only if you want to migrate writetimes and TTLs
"spark.migrate.source.ttl.cols" - Comma separated column indexes from "spark.migrate.query.cols.select". Script will only use the largest value per row.
Include "writetime(column-name)" in "spark.migrate.query.cols.select" only if you want to use "writeTimeStampFilter" filter
"spark.migrate.source.writeTimeStampFilter.cols" - Comma separated column indexes from "spark.migrate.query.cols.select". Script will only use the largest value per row.
Default value for "spark.migrate.source.maxWriteTimeStampFilter" is alway "9223372036854775807" (max long value)
Properties "spark.migrate.query.cols.insert" and "spark.migrate.query.cols.insert.types" are required for "Migrate" job, however they can be left empty for "DiffData" job

Frozen has no impact on the mapping of Collections (Map/List/Set) - Example: 5%1%0 for frozen<map<int, text>>

Following are the supported data types and their corresponding [Cassandra data-types]
 0: String [ascii, text, varchar]
 1: Integer [int, smallint]
 2: Long [bigint]
 3: Double [double]
 4: Instant [time, timestamp]
 5: Map (separate type by %) [map] - Example: 5%1%0 for map<int, text>
 6: List (separate type by %) [list] - Example: 6%0 for list<text> 
 7: ByteBuffer [blob]
 8: Set (seperate type by %) [set] - Example: 8%0 for set<text> 
 9: UUID [uuid, timeuuid]
10: Boolean [boolean]
11: TupleValue [tuple]
12: Float (float)
13: TinyInt [tinyint]
14: BigDecimal (decimal)
*/
